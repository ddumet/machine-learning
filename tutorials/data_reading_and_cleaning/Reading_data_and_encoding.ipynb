{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and encoding\n",
    "This notebook describes how to read and decode data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources (or extract of data sources) used in this notebook\n",
    "* Extract (rows for 31/12/2017): NFL play by play data (from **Kaggle**: [Detailed NFL Play-by-Play Data 2009-2017](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files with correct encoding\n",
    "____\n",
    "\n",
    "Character encodings are specific sets of rules for mapping from raw binary byte strings (that look like this: 0110100001101001) to characters that make up human-readable text (like \"hi\"). There are many different encodings, and if you tried to read in text with a different encoding that the one it was originally written in, you ended up with scrambled text called \"mojibake\" (said like mo-gee-bah-kay). Here's an example of mojibake:\n",
    "\n",
    "æ–‡å—åŒ–ã??\n",
    "\n",
    "You might also end up with a \"unknown\" characters. There are what gets printed when there's no mapping between a particular byte and a character in the encoding you're using to read your byte string in and they look like this:\n",
    "\n",
    "����������\n",
    "\n",
    "Character encoding mismatches are less common today than they used to be, but it's definitely still a problem. There are lots of different character encodings, but the main one you need to know is UTF-8.\n",
    "\n",
    "> **UTF-8 is the standard text encoding**. All Python code is in UTF-8 and, ideally, all your data should be as well. It's when things aren't in UTF-8 that you run into trouble.\n",
    "\n",
    "Strings can be encoded/decoded differently using ```str.encode``` or ```str.decode```:\n",
    "* ```str.encode``` returns data of type **bytes** encoded in the specified encoding.\n",
    "* ```str.decode``` returns a str decoded as the specified encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before is of type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "before = \"This is the euro symbol: €\"\n",
    "print(\"before is of type {}\".format(type(before)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after is of type <class 'bytes'> and reads as [b'This is the euro symbol: \\xe2\\x82\\xac']\n"
     ]
    }
   ],
   "source": [
    "after = before.encode(\"utf-8\", errors = \"replace\")\n",
    "print(\"after is of type {0} and reads as [{1}]\".format(type(after),after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note the \"**\\xe2\\x82\\xac**\" replacing the \"**€**\" character. That's because bytes are printed as they were ascii characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting to read/decode data with the wrong encoding will usually returns error:\n",
    "Here, attempting to read the **UTF-8** encoded ```bytes``` as **ascii**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4bf4b16e1feb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ascii\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```errors = \"replace\"``` replaces character that cannot be encoded in the specified format with the format byte string for the unknown character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: ?\n"
     ]
    }
   ],
   "source": [
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the encoding of a file and reading it\n",
    "When reading a file we don't usually know which encoding is used. One way to figure it out is to try and test a bunch of different character encodings and see if any of them work. A better way, though, is to use the chardet module to try and automatically guess what the right encoding is. It's not 100% guaranteed to be right, but it's usually faster than just trying to guess.\n",
    "\n",
    "The process is to read a certain numbers of bytes from the file and let ```chardet``` find out which encoding is used for the file. It's generally enough to look at the first ten thousand bytes of a file for ```chardet``` to be able to give a good guess and is much faster than trying to look at the whole file. (Especially with a  large file this can be very slow). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'UTF-8-SIG', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/NFL_Play_by_Play_2009-2017_(v4)_extract.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(500))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case, ```chardet``` is 100% confident the encoding is UTF-8.\n",
    "We can then read the file with ```encoding = \"utf-8\"``` (which is actually the default for ```pandas.read_csv```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2801, 102)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/NFL_Play_by_Play_2009-2017_(v4)_extract.csv\", encoding=\"utf-8\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources\n",
    "* [**ftfy** (fixes text for you)](https://ftfy.readthedocs.io/en/latest/): **ftfy** fixes Unicode that’s broken in various ways. The goal of ftfy is to take in bad Unicode and output good Unicode, for use in your Unicode-aware code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
